{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd64fd4-f253-42ba-a85a-4e83688be7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "# Crear sesión de Spark si no la tienes ya\n",
    "spark = SparkSession.builder.appName(\"AnalisisVentas\").getOrCreate()\n",
    "\n",
    "# Cargar el archivo CSV\n",
    "df = spark.read.csv(\"work/FactVentas.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18c58fd7-bc99-416c-a34f-fbffb92df92f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+------------------+\n",
      "|ID_Producto|Cantidad_Total|       Venta_Total|\n",
      "+-----------+--------------+------------------+\n",
      "|        148|            60|439.59000000000003|\n",
      "|         31|            70|            257.04|\n",
      "|        137|            74|            749.54|\n",
      "|         85|           100|1453.4500000000003|\n",
      "|         65|            70|            381.94|\n",
      "|         53|           101|           1423.86|\n",
      "|        133|            73|1380.8100000000002|\n",
      "|         78|           122|           1723.34|\n",
      "|        108|            66| 364.7100000000001|\n",
      "|         34|            61|            784.78|\n",
      "|        115|            51| 474.6100000000001|\n",
      "|        126|            66|            708.45|\n",
      "|        101|            33|            477.61|\n",
      "|         81|            69| 940.7700000000002|\n",
      "|         28|            55| 788.6899999999999|\n",
      "|         76|            74|1412.1000000000004|\n",
      "|         26|           101| 723.5600000000001|\n",
      "|         27|           103|2126.4100000000003|\n",
      "|         44|            57|            514.85|\n",
      "|        103|           120|            1162.8|\n",
      "+-----------+--------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "ventas_por_producto = df.groupBy(\"ID_Producto\") \\\n",
    "    .agg({\"Cantidad\": \"sum\", \"Total_Venta\": \"sum\"}) \\\n",
    "    .withColumnRenamed(\"sum(Cantidad)\", \"Cantidad_Total\") \\\n",
    "    .withColumnRenamed(\"sum(Total_Venta)\", \"Venta_Total\")\n",
    "\n",
    "ventas_por_producto.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c22e52ec-e386-4282-ba94-b8de7d0708da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "# Convertir columnas numéricas en vector de entrada\n",
    "assembler = VectorAssembler(\n",
    "    inputCols=[\"Cantidad_Total\", \"Venta_Total\"],\n",
    "    outputCol=\"features\"\n",
    ")\n",
    "\n",
    "data_cluster = assembler.transform(ventas_por_producto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5ba072ed-3d2d-4b17-8280-2b3fa12dfe74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+------------------+-------+\n",
      "|ID_Producto|Cantidad_Total|       Venta_Total|cluster|\n",
      "+-----------+--------------+------------------+-------+\n",
      "|        148|            60|439.59000000000003|      1|\n",
      "|         31|            70|            257.04|      1|\n",
      "|        137|            74|            749.54|      0|\n",
      "|         85|           100|1453.4500000000003|      2|\n",
      "|         65|            70|            381.94|      1|\n",
      "|         53|           101|           1423.86|      2|\n",
      "|        133|            73|1380.8100000000002|      2|\n",
      "|         78|           122|           1723.34|      2|\n",
      "|        108|            66| 364.7100000000001|      1|\n",
      "|         34|            61|            784.78|      0|\n",
      "|        115|            51| 474.6100000000001|      1|\n",
      "|        126|            66|            708.45|      0|\n",
      "|        101|            33|            477.61|      1|\n",
      "|         81|            69| 940.7700000000002|      0|\n",
      "|         28|            55| 788.6899999999999|      0|\n",
      "|         76|            74|1412.1000000000004|      2|\n",
      "|         26|           101| 723.5600000000001|      0|\n",
      "|         27|           103|2126.4100000000003|      2|\n",
      "|         44|            57|            514.85|      1|\n",
      "|        103|           120|            1162.8|      0|\n",
      "+-----------+--------------+------------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.ml.clustering import KMeans\n",
    "\n",
    "kmeans = KMeans(k=3, seed=1, featuresCol=\"features\", predictionCol=\"cluster\")\n",
    "modelo = kmeans.fit(data_cluster)\n",
    "resultado = modelo.transform(data_cluster)\n",
    "\n",
    "resultado.select(\"ID_Producto\", \"Cantidad_Total\", \"Venta_Total\", \"cluster\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ccaf2771-4909-4c10-860c-81aea3e602ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultado.select(\"ID_Producto\", \"Cantidad_Total\", \"Venta_Total\", \"cluster\") \\\n",
    "    .toPandas().to_csv(\"/home/jovyan/work/segmentacion_productos.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3360c6a9-1ac3-4910-8b78-29eb9bd1161a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+----------------+------------------+------------------+\n",
      "|ID_Sucursal|CantidadSucursal|     TotalSucursal|    TicketPromedio|\n",
      "+-----------+----------------+------------------+------------------+\n",
      "|          1|            1801|          21962.65|12.194697390338701|\n",
      "|          6|            1822| 22609.26999999999|12.409039517014264|\n",
      "|          3|            1595|19364.449999999997|12.140721003134795|\n",
      "|          5|            1830|22992.919999999987| 12.56443715846994|\n",
      "|          4|            1644|          19106.99|11.622256690997569|\n",
      "|          2|            1530|18231.369999999977|11.915928104575148|\n",
      "+-----------+----------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "ventas_sucursal = df.groupBy(\"ID_Sucursal\") \\\n",
    "    .agg({\"Total_Venta\": \"sum\", \"Cantidad\": \"sum\"}) \\\n",
    "    .withColumnRenamed(\"sum(Total_Venta)\", \"TotalSucursal\") \\\n",
    "    .withColumnRenamed(\"sum(Cantidad)\", \"CantidadSucursal\") \\\n",
    "    .withColumn(\"TicketPromedio\", col(\"TotalSucursal\") / col(\"CantidadSucursal\"))\n",
    "\n",
    "ventas_sucursal.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c49e402d-34b4-4771-8aac-5b639a5e7c11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|Mes|  sum(Total_Venta)|\n",
      "+---+------------------+\n",
      "|  1| 21568.70999999999|\n",
      "|  2| 19775.99999999999|\n",
      "|  3|19870.000000000004|\n",
      "|  4|15819.119999999997|\n",
      "|  5|12099.439999999997|\n",
      "|  6| 5112.180000000002|\n",
      "|  7|5804.0199999999995|\n",
      "|  8| 4684.899999999999|\n",
      "|  9|           5438.56|\n",
      "| 10| 3843.790000000001|\n",
      "| 11| 4677.189999999999|\n",
      "| 12| 5573.739999999999|\n",
      "+---+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import month\n",
    "\n",
    "ventas_por_mes = df.withColumn(\"Mes\", month(\"Fecha\")) \\\n",
    "    .groupBy(\"Mes\") \\\n",
    "    .sum(\"Total_Venta\") \\\n",
    "    .orderBy(\"Mes\")\n",
    "\n",
    "ventas_por_mes.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03d3541a-9690-493e-80aa-679799703091",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_sucursal.toPandas().to_csv(\"/home/jovyan/work/ventas_por_sucursal.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402d9b26-3ef6-4468-bf82-9a1c8e8d890e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----------------+-------+\n",
      "|ID_Producto|Cantidad_Total|      Venta_Total|cluster|\n",
      "+-----------+--------------+-----------------+-------+\n",
      "|         64|            31|           688.65|      0|\n",
      "|         10|            67|           874.52|      0|\n",
      "|        117|            67|           632.59|      0|\n",
      "|         48|            70|772.3099999999998|      0|\n",
      "|         43|            90|          1161.52|      0|\n",
      "|         34|            61|           784.78|      0|\n",
      "|         61|           106|          1060.28|      0|\n",
      "|         81|            69|940.7700000000002|      0|\n",
      "|        127|            73|730.0999999999999|      0|\n",
      "|         26|           101|723.5600000000001|      0|\n",
      "|        107|            69|884.9300000000003|      0|\n",
      "|         12|           100|            714.9|      0|\n",
      "|         17|            77|798.3000000000002|      0|\n",
      "|         93|            72|          1152.16|      0|\n",
      "|          9|            71|           768.36|      0|\n",
      "|         52|            53|           1053.3|      0|\n",
      "|         72|            77|          1086.97|      0|\n",
      "|         86|            51|891.9900000000001|      0|\n",
      "|        114|            83|681.1599999999999|      0|\n",
      "|        120|            72|          1086.48|      0|\n",
      "+-----------+--------------+-----------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "resultado.select(\"ID_Producto\", \"Cantidad_Total\", \"Venta_Total\", \"cluster\").orderBy(\"cluster\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aabca32f-7065-4581-b8a1-d431f316a01f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------+--------------------+-----------+\n",
      "|ID_Venta|  NombreProducto|              Nombre|Total_Venta|\n",
      "+--------+----------------+--------------------+-----------+\n",
      "|       1|Guantes de Látex|Sucursal La Libertad|      27.18|\n",
      "|       2|  Enjuague Bucal| Sucursal San Miguel|      50.19|\n",
      "|       3|Guantes de Látex|  Sucursal Santa Ana|      19.88|\n",
      "|       4|Vendas Elásticas|    Sucursal Escalón|       9.17|\n",
      "|       5|Mascarillas KN95|Sucursal La Libertad|      11.48|\n",
      "+--------+----------------+--------------------+-----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cargar otras tablas\n",
    "productos = spark.read.csv(\"work/DimProducto.csv\", header=True, inferSchema=True)\n",
    "sucursales = spark.read.csv(\"work/DimSucursal.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Unir productos con ventas\n",
    "ventas_enriquecidas = df.join(productos, df.ID_Producto == productos.ID_Producto) \\\n",
    "                        .join(sucursales, df.ID_Sucursal == sucursales.ID_Sucursal)\n",
    "\n",
    "ventas_enriquecidas.select(\"ID_Venta\", \"NombreProducto\", \"Nombre\", \"Total_Venta\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775f838d-76b3-4024-8e8f-875e4802b55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+-----------+-------------------+\n",
      "|ID_Producto|Cantidad_Total|StockActual|           Rotacion|\n",
      "+-----------+--------------+-----------+-------------------+\n",
      "|        148|            60|        272|0.22058823529411764|\n",
      "|        148|            60|        120|                0.5|\n",
      "|        148|            60|         45| 1.3333333333333333|\n",
      "|         31|            70|        240| 0.2916666666666667|\n",
      "|         31|            70|        325| 0.2153846153846154|\n",
      "|         85|           100|        176| 0.5681818181818182|\n",
      "|         85|           100|        115| 0.8695652173913043|\n",
      "|         65|            70|        154|0.45454545454545453|\n",
      "|         65|            70|        240| 0.2916666666666667|\n",
      "|         53|           101|        111| 0.9099099099099099|\n",
      "|         53|           101|        218|  0.463302752293578|\n",
      "|        133|            73|         89| 0.8202247191011236|\n",
      "|        133|            73|        443|0.16478555304740405|\n",
      "|        108|            66|        195| 0.3384615384615385|\n",
      "|        108|            66|         67| 0.9850746268656716|\n",
      "|         34|            61|        387|0.15762273901808785|\n",
      "|        115|            51|        335|0.15223880597014924|\n",
      "|        115|            51|        449|0.11358574610244988|\n",
      "|        115|            51|        120|              0.425|\n",
      "|        115|            51|        359|0.14206128133704735|\n",
      "+-----------+--------------+-----------+-------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "inventario = spark.read.csv(\"work/DimInventario.csv\", header=True, inferSchema=True)\n",
    "\n",
    "\n",
    "# Join con producto\n",
    "ventas_stock = ventas_por_producto.join(inventario, \"ID_Producto\")\n",
    "\n",
    "# Calcular rotación = ventas / stock\n",
    "ventas_stock = ventas_stock.withColumn(\"Rotacion\", col(\"Cantidad_Total\") / col(\"StockActual\"))\n",
    "\n",
    "ventas_stock.select(\"ID_Producto\", \"Cantidad_Total\", \"StockActual\", \"Rotacion\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2afa8df-d3a2-480f-8136-5d9391b507a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------------+\n",
      "|Mes|  Ventas_Mensuales|\n",
      "+---+------------------+\n",
      "|  1| 21568.70999999999|\n",
      "|  2| 19775.99999999999|\n",
      "|  3|19870.000000000004|\n",
      "|  4|15819.119999999997|\n",
      "|  5|12099.439999999997|\n",
      "|  6| 5112.180000000002|\n",
      "|  7|5804.0199999999995|\n",
      "|  8| 4684.899999999999|\n",
      "|  9|           5438.56|\n",
      "| 10| 3843.790000000001|\n",
      "| 11| 4677.189999999999|\n",
      "| 12| 5573.739999999999|\n",
      "+---+------------------+\n",
      "\n",
      "+----+---+------------------+\n",
      "| Año|Mes|    Ventas_Por_Mes|\n",
      "+----+---+------------------+\n",
      "|2023|  1| 5168.200000000001|\n",
      "|2023|  2| 4528.550000000001|\n",
      "|2023|  3|5582.5599999999995|\n",
      "|2023|  4|           4156.23|\n",
      "|2023|  5|            4786.5|\n",
      "|2023|  6| 5112.180000000002|\n",
      "|2023|  7|5804.0199999999995|\n",
      "|2023|  8| 4684.899999999999|\n",
      "|2023|  9|           5438.56|\n",
      "|2023| 10| 3843.790000000001|\n",
      "|2023| 11| 4677.189999999999|\n",
      "|2023| 12| 5573.739999999999|\n",
      "|2024|  1|          16400.51|\n",
      "|2024|  2|          15247.45|\n",
      "|2024|  3|14287.440000000008|\n",
      "|2024|  4|11662.890000000001|\n",
      "|2024|  5| 7312.939999999999|\n",
      "+----+---+------------------+\n",
      "\n",
      "+------+------------------+\n",
      "|Semana|  Ventas_Semanales|\n",
      "+------+------------------+\n",
      "|     1| 5127.899999999999|\n",
      "|     2| 4737.740000000002|\n",
      "|     3|           5040.62|\n",
      "|     4| 4923.450000000002|\n",
      "|     5| 4923.809999999999|\n",
      "|     6| 4507.900000000002|\n",
      "|     7| 5996.550000000001|\n",
      "|     8| 4223.960000000001|\n",
      "|     9|            4026.9|\n",
      "|    10| 4006.059999999999|\n",
      "|    11|4494.5599999999995|\n",
      "|    12|3838.5999999999995|\n",
      "|    13| 5379.679999999999|\n",
      "|    14|3580.4199999999996|\n",
      "|    15|4025.2999999999997|\n",
      "|    16|2735.9799999999996|\n",
      "|    17|           4406.93|\n",
      "|    18| 4720.999999999999|\n",
      "|    19| 4603.749999999998|\n",
      "|    20|           1811.14|\n",
      "+------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col\n",
    "\n",
    "# Paso 1: Cargar archivo de fechas \n",
    "fechas = spark.read.csv(\"work/DimFecha.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Paso 2: Hacer join entre ventas y fechas\n",
    "ventas_fechadas = df.join(fechas, df.ID_Fecha == fechas.ID_Fecha)\n",
    "\n",
    "# Paso 3: Agrupar por mes\n",
    "ventas_mes = ventas_fechadas.groupBy(\"Mes\") \\\n",
    "    .sum(\"Total_Venta\") \\\n",
    "    .withColumnRenamed(\"sum(Total_Venta)\", \"Ventas_Mensuales\") \\\n",
    "    .orderBy(\"Mes\")\n",
    "\n",
    "ventas_mes.show()\n",
    "\n",
    "# Paso 4 : Agrupar por Año y Mes\n",
    "ventas_anyo_mes = ventas_fechadas.groupBy(\"Año\", \"Mes\") \\\n",
    "    .sum(\"Total_Venta\") \\\n",
    "    .withColumnRenamed(\"sum(Total_Venta)\", \"Ventas_Por_Mes\") \\\n",
    "    .orderBy(\"Año\", \"Mes\")\n",
    "\n",
    "ventas_anyo_mes.show()\n",
    "\n",
    "# Paso 5 : Agrupar por Semana\n",
    "ventas_semana = ventas_fechadas.groupBy(\"Semana\") \\\n",
    "    .sum(\"Total_Venta\") \\\n",
    "    .withColumnRenamed(\"sum(Total_Venta)\", \"Ventas_Semanales\") \\\n",
    "    .orderBy(\"Semana\")\n",
    "\n",
    "ventas_semana.show()\n",
    "\n",
    "# Paso 6 : Exportar ventas por mes \n",
    "ventas_anyo_mes.toPandas().to_csv(\"/home/jovyan/work/ventas_por_mes.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "91a6596d-2cff-49be-a784-bcfb36f3acc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_mes.toPandas().to_csv(\"/home/jovyan/work/ventas_por_mes_simple.csv\", index=False)\n",
    "ventas_semana.toPandas().to_csv(\"/home/jovyan/work/ventas_por_semana.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd3197e-bc13-4f99-84b7-86aec82da935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------------+\n",
      "|       Categoria|     VentasTotales|\n",
      "+----------------+------------------+\n",
      "|     Medicamento| 61454.97999999998|\n",
      "|         Higiene|21914.890000000003|\n",
      "|      Suplemento| 20733.24999999999|\n",
      "|Cuidado Personal|          20164.53|\n",
      "+----------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# Análisis por Categoría de Producto\n",
    "# --------------------------------------------\n",
    "\n",
    "# Cargar DimProducto \n",
    "productos = spark.read.csv(\"work/DimProducto.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Unir ventas con productos\n",
    "ventas_categoria = df.join(productos, \"ID_Producto\")\n",
    "\n",
    "# Agrupar por categoría\n",
    "ventas_por_categoria = ventas_categoria.groupBy(\"Categoria\") \\\n",
    "    .sum(\"Total_Venta\") \\\n",
    "    .withColumnRenamed(\"sum(Total_Venta)\", \"VentasTotales\") \\\n",
    "    .orderBy(\"VentasTotales\", ascending=False)\n",
    "\n",
    "ventas_por_categoria.show()\n",
    "\n",
    "# Guardar CSV\n",
    "ventas_por_categoria.toPandas().to_csv(\"/home/jovyan/work/ventas_por_categoria.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823f07bf-0b69-47a6-b988-ad5beced7272",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-----------+---------------+-----------+--------------------+-------------+--------------+\n",
      "|ID_Producto|ID_Sucursal|CantidadVendida|StockActual|            Rotacion|NivelDeRiesgo|FechaDeRestock|\n",
      "+-----------+-----------+---------------+-----------+--------------------+-------------+--------------+\n",
      "|         48|          6|             18|        362|0.049723756906077346|         BAJO|    2025-06-27|\n",
      "|         62|          1|              6|        105| 0.05714285714285714|         BAJO|    2025-06-16|\n",
      "|        105|          1|             20|        435| 0.04597701149425287|         BAJO|    2025-06-20|\n",
      "|         91|          6|             11|         30| 0.36666666666666664|         BAJO|    2025-08-02|\n",
      "|         16|          3|              5|        353|0.014164305949008499|         BAJO|    2025-07-19|\n",
      "|        112|          2|             13|        481| 0.02702702702702703|         BAJO|    2025-07-25|\n",
      "|          6|          1|             21|         19|   1.105263157894737|         ALTO|    2025-07-12|\n",
      "|        102|          4|              1|         63|0.015873015873015872|         BAJO|    2025-06-08|\n",
      "|        102|          6|              4|        385| 0.01038961038961039|         BAJO|    2025-06-23|\n",
      "|         48|          1|              4|        386|0.010362694300518135|         BAJO|    2025-06-09|\n",
      "|        108|          2|             23|         67| 0.34328358208955223|         BAJO|    2025-06-23|\n",
      "|          7|          4|              5|        168| 0.02976190476190476|         BAJO|    2025-06-11|\n",
      "|         66|          3|             26|        400|               0.065|         BAJO|    2025-07-10|\n",
      "|         96|          5|              8|         72|  0.1111111111111111|         BAJO|    2025-07-05|\n",
      "|         69|          2|             32|        236| 0.13559322033898305|         BAJO|    2025-06-25|\n",
      "|         95|          3|              2|        298|0.006711409395973154|         BAJO|    2025-07-29|\n",
      "|         62|          6|              1|         55| 0.01818181818181818|         BAJO|    2025-06-28|\n",
      "|        143|          5|              8|        231| 0.03463203463203463|         BAJO|    2025-07-26|\n",
      "|         72|          1|             16|        296| 0.05405405405405406|         BAJO|    2025-08-01|\n",
      "|         44|          5|             10|        361|0.027700831024930747|         BAJO|    2025-07-24|\n",
      "+-----------+-----------+---------------+-----------+--------------------+-------------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --------------------------------------------\n",
    "# Productos en Riesgo de Agotarse\n",
    "# --------------------------------------------\n",
    "\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Unir ventas con inventario \n",
    "ventas_por_producto = df.groupBy(\"ID_Producto\", \"ID_Sucursal\") \\\n",
    "    .agg({\"Cantidad\": \"sum\"}) \\\n",
    "    .withColumnRenamed(\"sum(Cantidad)\", \"CantidadVendida\")\n",
    "\n",
    "inventario = spark.read.csv(\"work/DimInventario.csv\", header=True, inferSchema=True)\n",
    "\n",
    "ventas_stock = ventas_por_producto.join(inventario, [\"ID_Producto\", \"ID_Sucursal\"])\n",
    "\n",
    "# Calcular rotación\n",
    "ventas_stock = ventas_stock.withColumn(\"Rotacion\", col(\"CantidadVendida\") / col(\"StockActual\"))\n",
    "\n",
    "# Clasificar nivel de riesgo\n",
    "ventas_stock = ventas_stock.withColumn(\n",
    "    \"NivelDeRiesgo\",\n",
    "    when((col(\"Rotacion\") >= 1) & (col(\"StockActual\") <= 200), \"ALTO\")\n",
    "    .when((col(\"Rotacion\") >= 0.5) & (col(\"StockActual\") <= 300), \"MEDIO\")\n",
    "    .otherwise(\"BAJO\")\n",
    ")\n",
    "\n",
    "# Mostrar tabla completa con riesgo\n",
    "ventas_stock.select(\"ID_Producto\", \"ID_Sucursal\", \"CantidadVendida\", \"StockActual\", \"Rotacion\", \"NivelDeRiesgo\", \"FechaDeRestock\").show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e9f69b0f-b0d6-4fba-8555-912bbb193cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ventas_stock.select(\n",
    "    \"ID_Producto\", \"ID_Sucursal\", \"CantidadVendida\",\n",
    "    \"StockActual\", \"Rotacion\", \"NivelDeRiesgo\", \"FechaDeRestock\"\n",
    ").toPandas().to_csv(\"/home/jovyan/work/productos_nivel_riesgo.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0205dc96-22f3-4b7f-a6b9-c617cda4fe1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+---+---------------+\n",
      "|ID_Producto|Mes|CantidadMensual|\n",
      "+-----------+---+---------------+\n",
      "|        104|  2|              1|\n",
      "|         67|  4|              1|\n",
      "|         35| 10|              1|\n",
      "|        141| 10|              1|\n",
      "|        138|  9|              1|\n",
      "|         68| 11|              1|\n",
      "|         45|  6|              1|\n",
      "|        139| 11|              1|\n",
      "|         14|  6|              1|\n",
      "|        120| 10|              1|\n",
      "|         58|  9|              1|\n",
      "|         45|  5|              1|\n",
      "|         44|  6|              1|\n",
      "|         43|  3|              1|\n",
      "|         25|  6|              1|\n",
      "|        115|  1|              1|\n",
      "|         62|  2|              1|\n",
      "|        130| 12|              1|\n",
      "|         22|  6|              1|\n",
      "|        125|  9|              1|\n",
      "+-----------+---+---------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#baja rotacion mensual\n",
    "# Paso 1: Cargar DimFecha si no lo hiciste ya\n",
    "fechas = spark.read.csv(\"work/DimFecha.csv\", header=True, inferSchema=True)\n",
    "\n",
    "# Paso 2: Unir ventas con fecha\n",
    "ventas_fechadas = df.join(fechas, df.ID_Fecha == fechas.ID_Fecha)\n",
    "\n",
    "# Paso 3: Agrupar por producto y mes\n",
    "ventas_mensuales = ventas_fechadas.groupBy(\"ID_Producto\", \"Mes\") \\\n",
    "    .sum(\"Cantidad\") \\\n",
    "    .withColumnRenamed(\"sum(Cantidad)\", \"CantidadMensual\")\n",
    "\n",
    "# Paso 4: Filtrar productos con baja rotación\n",
    "productos_baja_rotacion = ventas_mensuales.filter(col(\"CantidadMensual\") < 5)\n",
    "\n",
    "# Mostrar resultado\n",
    "productos_baja_rotacion.orderBy(\"CantidadMensual\").show()\n",
    "\n",
    "# Exportar a CSV\n",
    "productos_baja_rotacion.toPandas().to_csv(\"/home/jovyan/work/productos_baja_rotacion_mensual.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5339dd1f-5f89-4fcd-820c-65c5d5ae93b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
